{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark DataFrame Project.ipynbWk9",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO6XnMkJ5egfSG0A7s73rmL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fkivuti/project_pyspark/blob/main/Spark_DataFrame_Project_ipynbWk9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b> Prerequisite <b/>\n",
        "\n"
      ],
      "metadata": {
        "id": "7Mi-mSgdLYOS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform an analysis by answering questions about\n",
        "some stock market data on Safaricom from the years 2012-2017."
      ],
      "metadata": {
        "id": "l08-eDoTOHuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install necessary libraries"
      ],
      "metadata": {
        "id": "fWZbcrvsMJe5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WrXDMWayJVmP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "153575be-1492-4af3-a908-0ecb1bdfa505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 33 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 53.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=0db58d28be446413cdf628dfdc8766667c8634ae896b1d35bc031b71d11527bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ],
      "source": [
        "# Installing pyspark\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run a local spark session\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "8SYnSbxlMARK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZsHq0DmgOul5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preview first 5 lines of the csv file"
      ],
      "metadata": {
        "id": "Xz_r9mVYPfLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first 4 lines of the file saf_stock.csv\n",
        "with open ('saf_stock.csv') as f:\n",
        "  for i in range(0,5):\n",
        "    print(f.readline())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNgREH8HN4V2",
        "outputId": "2835ce66-537d-4814-eeb9-49e35fe262bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date,Open,High,Low,Close,Volume,Adj Close\n",
            "\n",
            "2012-01-03,59.970001,61.060001,59.869999,60.330002,12668800,52.619234999999996\n",
            "\n",
            "2012-01-04,60.209998999999996,60.349998,59.470001,59.709998999999996,9593300,52.078475\n",
            "\n",
            "2012-01-05,59.349998,59.619999,58.369999,59.419998,12768200,51.825539\n",
            "\n",
            "2012-01-06,59.419998,59.450001,58.869999,59.0,8069400,51.45922\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the data into a dataframe"
      ],
      "metadata": {
        "id": "yjp6oQuPPmNX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display column headers"
      ],
      "metadata": {
        "id": "p8OdkVulOw6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the saf_stock.csv file\n",
        "from pyspark.sql import SQLContext\n",
        "\n",
        "# Pass in the SparkContext object `sqlCtx`\n",
        "sqlCtx = SQLContext(sc)\n",
        "\n",
        "# Read csv data into a DataFrame object `df`\n",
        "df = sqlCtx.read.csv(\"saf_stock.csv\", header = True)\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqFGUA5CO9Go",
        "outputId": "0a1d7a24-0ed5-416d-e7a0-cc98eb1d7d2c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:79: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show df type\n",
        "print(type(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zj0mjBLQQQC",
        "outputId": "d945d7b1-75df-4d3c-af5c-932adc019c53"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register the dataframe as a table"
      ],
      "metadata": {
        "id": "dBs2lb6eR9JQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the dataframe as a table and print the name\n",
        "df.createOrReplaceTempView('saf_stock')\n",
        "tables = sqlCtx.tableNames()\n",
        "print(tables)\n",
        "\n",
        "# df = sqlCtx.read.csv(\"saf_stock.csv\")\n",
        "# df.registerTempTable('saf_stock')\n",
        "# tables = sqlCtx.tableNames()\n",
        "# print(tables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77J2oRsaQxbE",
        "outputId": "d95060c8-dc81-4bdf-e694-45d9910f3d5e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['saf_stock']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview first 10 rows of the table\n",
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWrkoiMdRlAz",
        "outputId": "5fa5dd14-6b17-40b5-e0f3-365df3429209"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
            "|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|\n",
            "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
            "|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|\n",
            "|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|\n",
            "|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|\n",
            "|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994|\n",
            "|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|\n",
            "|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|\n",
            "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the statistcal summary\n",
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XlmsQW9AmLe",
        "outputId": "dc2f9e84-a669-4546-faab-2cb683bb07fd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|summary|      Date|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
            "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|  count|      1258|              1258|             1258|             1258|             1258|             1258|             1258|\n",
            "|   mean|      null| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
            "| stddev|      null|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
            "|    min|2012-01-03|56.389998999999996|        57.060001|        56.299999|        56.419998|         10010500|        50.363689|\n",
            "|    max|2016-12-30|         90.800003|        90.970001|            89.25|        90.470001|          9994400|84.91421600000001|\n",
            "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "eBAwlUkqBLLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import col function for column manipulation\n",
        "from pyspark.sql.functions import col, format_number\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "df_rounded=df.select(df['Date'],\n",
        "              format_number(df['Open'].cast('float'),2).alias('Open'),\n",
        "              format_number(df['High'].cast('float'), 2).alias('High'),\n",
        "              format_number(df['Low'].cast('float'), 2).alias('Low'),\n",
        "              format_number(df['Close'].cast('float'), 2).alias('Close'),\n",
        "              df['Volume'].cast('int').alias('Volume'),\n",
        "              format_number(df['Adj Close'].cast('float'), 2).alias('Adj Close')\n",
        "              )\n",
        "\n",
        "df_rounded.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdSIVwS3k9eW",
        "outputId": "5a7eea04-1c36-45e0-b009-19e9355c9613"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+-----+-----+--------+---------+\n",
            "|      Date| Open| High|  Low|Close|  Volume|Adj Close|\n",
            "+----------+-----+-----+-----+-----+--------+---------+\n",
            "|2012-01-03|59.97|61.06|59.87|60.33|12668800|    52.62|\n",
            "|2012-01-04|60.21|60.35|59.47|59.71| 9593300|    52.08|\n",
            "|2012-01-05|59.35|59.62|58.37|59.42|12768200|    51.83|\n",
            "|2012-01-06|59.42|59.45|58.87|59.00| 8069400|    51.46|\n",
            "|2012-01-09|59.03|59.55|58.92|59.18| 6679300|    51.62|\n",
            "|2012-01-10|59.43|59.71|58.98|59.04| 6907300|    51.49|\n",
            "|2012-01-11|59.06|59.53|59.04|59.40| 6365600|    51.81|\n",
            "|2012-01-12|59.79|60.00|59.40|59.50| 7236400|    51.90|\n",
            "|2012-01-13|59.18|59.61|59.01|59.54| 7729300|    51.93|\n",
            "|2012-01-17|59.87|60.11|59.52|59.85| 8500000|    52.20|\n",
            "+----------+-----+-----+-----+-----+--------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new data frame with a column called HV Ratio that is the ratio of the High Price versus volume of stock traded for a day.\n",
        "\n",
        "df_2 = df_rounded.withColumn(\"HV Ratio\",df_rounded['High']/df_rounded['Volume'])\n",
        "print(df_2.show(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6YePf3FB8jN",
        "outputId": "b09fe26c-cc2b-487c-ce9d-2dffb6934241"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+-----+-----+--------+---------+--------------------+\n",
            "|      Date| Open| High|  Low|Close|  Volume|Adj Close|            HV Ratio|\n",
            "+----------+-----+-----+-----+-----+--------+---------+--------------------+\n",
            "|2012-01-03|59.97|61.06|59.87|60.33|12668800|    52.62|4.819714574387472E-6|\n",
            "|2012-01-04|60.21|60.35|59.47|59.71| 9593300|    52.08|6.290848821573389...|\n",
            "|2012-01-05|59.35|59.62|58.37|59.42|12768200|    51.83|4.669413073103491E-6|\n",
            "|2012-01-06|59.42|59.45|58.87|59.00| 8069400|    51.46|7.367338339901356E-6|\n",
            "|2012-01-09|59.03|59.55|58.92|59.18| 6679300|    51.62|8.915604928660188E-6|\n",
            "|2012-01-10|59.43|59.71|58.98|59.04| 6907300|    51.49|8.644477581688938E-6|\n",
            "|2012-01-11|59.06|59.53|59.04|59.40| 6365600|    51.81| 9.35182857861003E-6|\n",
            "|2012-01-12|59.79|60.00|59.40|59.50| 7236400|    51.90| 8.29141562102703E-6|\n",
            "|2012-01-13|59.18|59.61|59.01|59.54| 7729300|    51.93|7.712211972623653E-6|\n",
            "|2012-01-17|59.87|60.11|59.52|59.85| 8500000|    52.20|7.071764705882352...|\n",
            "+----------+-----+-----+-----+-----+--------+---------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analysis"
      ],
      "metadata": {
        "id": "JoGzo1R8C28f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What day had the Peak High in Price?\n",
        "\n",
        "print(df_2.orderBy(df_2['High'].desc()).head(1)[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqdn1DQPOgnv",
        "outputId": "a6de7653-0e3d-4a4f-8a63-aa28840ce265"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2015-01-13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#What is the mean of the Close column?\n",
        "\n",
        "from pyspark.sql.functions import mean, max, min\n",
        "mean=df_2.select(mean('Close'))\n",
        "print(mean.show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcMnsScRQWJ4",
        "outputId": "a2cccc16-fff2-4797-ea22-4e73acb83f13"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|       avg(Close)|\n",
            "+-----------------+\n",
            "|72.38844992050863|\n",
            "+-----------------+\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the max and min of the Volume column?\n",
        "\n",
        "maxmin = df_2.select(max('Volume'),min('Volume'))\n",
        "print(maxmin.show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3fAQ7bTE9wQ",
        "outputId": "04ab6653-11cf-40e0-f44d-8f4dd5aff0e5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "|max(Volume)|min(Volume)|\n",
            "+-----------+-----------+\n",
            "|   80898100|    2094900|\n",
            "+-----------+-----------+\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many days was the Close lower than 60 dollars?\n",
        "\n",
        "lower_60 = df_2.filter(df_2['Close'] < 60).count()\n",
        "print(lower_60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAoFWQ6IHZ_b",
        "outputId": "bf14130d-08f9-451c-97d3-4a2331689384"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What percentage of the time was the High greater than 80 dollars?\n",
        "\n",
        "greater_80 = (df_2.filter(df_2['High']>80).count()/df.count()) * 100\n",
        "print(greater_80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU_M0QhpH0uZ",
        "outputId": "f6208f1b-079d-49da-89d2-7d7a51f0b06b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.426073131955485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the Pearson correlation between High and Volume?\n",
        "\n",
        "from pyspark.sql.functions import corr\n",
        "\n",
        "pcorr= df_2.select(corr('High','Volume'))\n",
        "print(pcorr.show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXqawc7ZISP-",
        "outputId": "92fb0e35-4c01-4b1b-8e5f-524d92a7a815"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|  corr(High, Volume)|\n",
            "+--------------------+\n",
            "|-0.33843260582148915|\n",
            "+--------------------+\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the max High per year?\n",
        "from pyspark.sql.functions import year\n",
        "\n",
        "df_2a=df_2.select(df_2['Date'],\n",
        "              df_2['High'].cast('float').alias('High'),\n",
        "              df_2['Close'].cast('float').alias('Close')\n",
        "              )\n",
        "\n",
        "df_2b = df_2a.withColumn(\"Year\",year(df_2['Date']))\n",
        "max_high = df_2b.groupBy('Year').max()\n",
        "print(max_high.select('Year','max(High)').orderBy('Year').show())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYtgIfZ5Ir5H",
        "outputId": "3ed97517-b2c8-40ac-d88c-cc8c4a83665c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+\n",
            "|Year|max(High)|\n",
            "+----+---------+\n",
            "|2012|     77.6|\n",
            "|2013|    81.37|\n",
            "|2014|    88.09|\n",
            "|2015|    90.97|\n",
            "|2016|    75.19|\n",
            "+----+---------+\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the average Close for each Calendar Month?\n",
        "\n",
        "from pyspark.sql.functions import month\n",
        "\n",
        "df_month = df_2b.withColumn('Month',month('Date'))\n",
        "avg_month = df_month.select(['Month','Close']).groupBy('Month').mean()\n",
        "print(avg_month.select('Month','avg(Close)').orderBy('Month').show(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wiqtiS4MFt5",
        "outputId": "62c9a764-1add-4742-9ecc-5f7aa6d55dbe"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+\n",
            "|Month|       avg(Close)|\n",
            "+-----+-----------------+\n",
            "|    1| 71.4480196131338|\n",
            "|    2|71.30680438169499|\n",
            "|    3|71.77794376266337|\n",
            "|    4|72.97361900692894|\n",
            "|    5|72.30971685445533|\n",
            "|    6| 72.4953774506191|\n",
            "|    7|74.43971944078106|\n",
            "|    8| 73.0298185521906|\n",
            "|    9|72.18411782208611|\n",
            "|   10| 71.5785454489968|\n",
            "+-----+-----------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary Findings"
      ],
      "metadata": {
        "id": "-tPMIFs3MbOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "● What day had the Peak High in Price? 2015-01-13\n",
        "\n",
        "● What is the mean of the Close column?  72.39\n",
        "\n",
        "● What is the max and min of the Volume column? Max 80898100  Min 2094900\n",
        "\n",
        "● How many days was the Close lower than 60 dollars? 81\n",
        "\n",
        "● What percentage of the time was the High greater than 80 dollars? 8.42\n",
        "\n",
        "● What is the Pearson correlation between High and Volume?  -0.34\n"
      ],
      "metadata": {
        "id": "UtG75C9IMflM"
      }
    }
  ]
}